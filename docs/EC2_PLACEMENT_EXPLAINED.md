# 🏗️ EC2 배치 및 연결 구조 (상세 설명)

**질문**:
1. 서브넷에 EC2를 하나씩 배치하는 거야?
2. ALB가 두 서브넷을 알아서 조율하는 거고?
3. MySQL EC2는 어떻게 연결되는 거야?

---

## 🎯 정확한 배치 구조

### 실제 물리적 배치

```
┌─────────────────────────────────────────────────────────────┐
│                  VPC (10.0.0.0/16)                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌───────────────────────────────────────────────────────┐  │
│  │ Public-AZ-A (10.0.1.0/24) - 가용영역 A               │  │
│  ├───────────────────────────────────────────────────────┤  │
│  │                                                       │  │
│  │  ┌──────────────┐                                    │  │
│  │  │ ALB (일부)   │  ← ALB는 여기에도 배치됨          │  │
│  │  └──────────────┘                                    │  │
│  │                                                       │  │
│  │  ┌──────────────────────────────────────┐            │  │
│  │  │ App Instance #1                      │            │  │
│  │  │ Private IP: 10.0.1.10               │            │  │
│  │  │ Public IP: 3.35.123.45              │            │  │
│  │  │ (ASG가 자동 배치)                    │            │  │
│  │  └──────────────────────────────────────┘            │  │
│  │                                                       │  │
│  │  ┌──────────────────────────────────────┐            │  │
│  │  │ MySQL Instance                       │            │  │
│  │  │ Private IP: 10.0.1.234 ⭐            │            │  │
│  │  │ Public IP: 3.35.200.100             │            │  │
│  │  │ (수동 배치, 고정 위치)                │            │  │
│  │  └──────────────────────────────────────┘            │  │
│  │                                                       │  │
│  └───────────────────────────────────────────────────────┘  │
│                                                             │
│  ┌───────────────────────────────────────────────────────┐  │
│  │ Public-AZ-C (10.0.2.0/24) - 가용영역 C               │  │
│  ├───────────────────────────────────────────────────────┤  │
│  │                                                       │  │
│  │  ┌──────────────┐                                    │  │
│  │  │ ALB (일부)   │  ← ALB는 여기에도 배치됨          │  │
│  │  └──────────────┘                                    │  │
│  │                                                       │  │
│  │  ┌──────────────────────────────────────┐            │  │
│  │  │ App Instance #2                      │            │  │
│  │  │ Private IP: 10.0.2.20               │            │  │
│  │  │ Public IP: 3.35.150.88              │            │  │
│  │  │ (ASG가 자동 배치)                    │            │  │
│  │  └──────────────────────────────────────┘            │  │
│  │                                                       │  │
│  └───────────────────────────────────────────────────────┘  │
│                                                             │
└─────────────────────────────────────────────────────────────┘

핵심:
  ✅ App 인스턴스: ASG가 두 AZ에 균등 분산 배치
  ✅ MySQL: 한 AZ에만 고정 배치 (10.0.1.234)
  ✅ ALB: 두 AZ 모두에 배치 (자동)
```

---

## 🔄 App 인스턴스 배치 (ASG 자동)

### Auto Scaling Group 설정

```yaml
ASG 설정:
  Name: feedback-asg
  Launch Template: feedback-app-template

  Subnets: ⭐
    - Public-AZ-A (10.0.1.0/24)
    - Public-AZ-C (10.0.2.0/24)

  Desired Capacity: 2
  Min: 1
  Max: 3
```

### ASG가 인스턴스를 배치하는 방법

```
Step 1: ASG가 인스턴스 2개 시작 필요
  Desired: 2, Min: 1, Max: 3

Step 2: AZ 균등 분산 (AZ Balancing) ⭐
  - 사용 가능한 AZ: 2개 (AZ-A, AZ-C)
  - 2개 인스턴스를 균등 분산

  → AZ-A에 1개
  → AZ-C에 1개

Step 3: 각 AZ의 Subnet에서 IP 할당
  - AZ-A Subnet (10.0.1.0/24)
    → 10.0.1.10 할당 (자동)

  - AZ-C Subnet (10.0.2.0/24)
    → 10.0.2.20 할당 (자동)

결과:
┌─────────────────────────────────────┐
│ Public-AZ-A                         │
│   └─ App #1 (10.0.1.10)            │
├─────────────────────────────────────┤
│ Public-AZ-C                         │
│   └─ App #2 (10.0.2.20)            │
└─────────────────────────────────────┘
```

### Auto Scaling 시 배치 동작

```
시나리오: CPU 70% 초과 → 3개로 확장

Before (2개):
  AZ-A: 1개 (App #1)
  AZ-C: 1개 (App #2)

ASG 판단:
  "3개 인스턴스를 2개 AZ에 균등 분산"
  → AZ-A: 2개
  → AZ-C: 1개
  또는
  → AZ-A: 1개
  → AZ-C: 2개

After (3개):
  AZ-A: 2개 (App #1, App #3)
  AZ-C: 1개 (App #2)

또는

  AZ-A: 1개 (App #1)
  AZ-C: 2개 (App #2, App #3)

→ ASG가 자동으로 균등 분산! ⭐
```

---

## 🌐 ALB 동작 방식

### ALB 자체 배치

```
ALB는 두 AZ 모두에 배치됩니다! ⭐

┌─────────────────────────────────────┐
│ Public-AZ-A                         │
│   └─ ALB Node A                     │
│      (10.0.1.5 같은 내부 IP)        │
├─────────────────────────────────────┤
│ Public-AZ-C                         │
│   └─ ALB Node C                     │
│      (10.0.2.5 같은 내부 IP)        │
└─────────────────────────────────────┘

사용자는 ALB DNS로 접근:
  feedback-alb-xxxxx.ap-northeast-2.elb.amazonaws.com

DNS 응답:
  - 10.0.1.5 (AZ-A의 ALB Node)
  - 10.0.2.5 (AZ-C의 ALB Node)

→ 클라이언트가 둘 중 하나로 랜덤 접속
→ 한쪽 AZ 장애 시 다른 쪽으로 자동 전환!
```

### ALB Target Group 연결

```
Target Group: feedback-tg
  Targets:
    - 10.0.1.10:8080 (App #1 in AZ-A) ✅
    - 10.0.2.20:8080 (App #2 in AZ-C) ✅

ALB 로드 밸런싱 알고리즘:
  - Round Robin (기본)
  - Least Outstanding Requests (선택 가능)

동작:
  Request 1 → App #1 (10.0.1.10)
  Request 2 → App #2 (10.0.2.20)
  Request 3 → App #1 (10.0.1.10)
  Request 4 → App #2 (10.0.2.20)
  ...

→ 두 인스턴스에 균등 분배! ⭐
```

---

## 🗄️ MySQL 배치 및 연결

### MySQL 배치 (수동, 고정)

```
MySQL은 한 AZ에만 배치:

선택: Public-AZ-A (10.0.1.0/24)

EC2 Launch:
  Name: mysql-server
  Subnet: Public-AZ-A ⭐
  Private IP: 10.0.1.234 (자동 할당, 고정됨)
  Public IP: 3.35.200.100 (자동 할당)

왜 한 곳만?
  ✅ 데이터베이스는 단일 마스터 (Primary)
  ✅ 2개 AZ에 배치하면 데이터 동기화 필요 (복잡!)
  ✅ 5일 데모에는 단순하게 1개만

프로덕션이라면?
  - Primary-Replica 구성 (AZ-A: Primary, AZ-C: Replica)
  - 또는 RDS Multi-AZ
```

### VPC 내부 통신 (핵심!) ⭐

```
VPC Route Table (10.0.0.0/16 → local):
┌─────────────────────────────────────────────┐
│ Destination     Target                      │
├─────────────────────────────────────────────┤
│ 10.0.0.0/16     local ⭐                     │
│ 0.0.0.0/0       igw-xxxxx                   │
└─────────────────────────────────────────────┘

의미:
  - VPC 내부 (10.0.0.0/16) 모든 IP는 로컬 통신
  - Subnet 상관없이 서로 접근 가능!
  - Internet Gateway 안 거침 (빠름!)

예시:
  App #1 (10.0.1.10, AZ-A)
    → MySQL (10.0.1.234, AZ-A)
    → 같은 AZ, 같은 Subnet
    → 직접 통신 ✅

  App #2 (10.0.2.20, AZ-C)
    → MySQL (10.0.1.234, AZ-A)
    → 다른 AZ, 다른 Subnet
    → 하지만 VPC 내부 (10.0.0.0/16)
    → Route Table: 10.0.0.0/16 → local
    → AWS 백본 네트워크로 직접 통신 ✅

→ AZ 달라도 VPC 내부면 통신 가능! ⭐
```

### MySQL 연결 흐름

```
App Instance #1 (AZ-A, 10.0.1.10):
  ↓
  SPRING_DATASOURCE_URL=jdbc:mysql://10.0.1.234:3306/feedbackdb
  ↓
  MySQL (AZ-A, 10.0.1.234)
  ✅ 연결 성공! (같은 AZ, 빠름!)

App Instance #2 (AZ-C, 10.0.2.20):
  ↓
  SPRING_DATASOURCE_URL=jdbc:mysql://10.0.1.234:3306/feedbackdb
  ↓
  Route Table: 10.0.1.234는 10.0.0.0/16 범위 → local
  ↓
  AWS 백본 네트워크 (AZ 간 연결)
  ↓
  MySQL (AZ-A, 10.0.1.234)
  ✅ 연결 성공! (다른 AZ지만 VPC 내부!)

Security Group 확인:
  db-sg (MySQL):
    Inbound: 3306 ← app-sg

  app-sg (App #1, App #2):
    Outbound: All

  → App #1, App #2 모두 MySQL 접근 허용 ✅
```

---

## 🔍 전체 연결 흐름

### 사용자 요청부터 응답까지

```
┌─────────────────────────────────────────────────────┐
│ Step 1: 사용자 요청                                 │
└─────────────────────────────────────────────────────┘

User (Internet)
  ↓ HTTP GET
  feedback-alb-xxxxx.ap-northeast-2.elb.amazonaws.com/api/feedbacks

┌─────────────────────────────────────────────────────┐
│ Step 2: DNS 조회 및 ALB 접근                        │
└─────────────────────────────────────────────────────┘

DNS 응답:
  - 10.0.1.5 (ALB in AZ-A)
  - 10.0.2.5 (ALB in AZ-C)

User → 10.0.1.5 (AZ-A의 ALB Node 선택됨)

┌─────────────────────────────────────────────────────┐
│ Step 3: ALB → Target 선택 (로드 밸런싱)             │
└─────────────────────────────────────────────────────┘

ALB (AZ-A):
  Target Group 확인:
    - 10.0.1.10:8080 (healthy)
    - 10.0.2.20:8080 (healthy)

  Round Robin → 10.0.2.20 선택 (AZ-C의 App #2)
  ↓
  HTTP GET → 10.0.2.20:8080/api/feedbacks

┌─────────────────────────────────────────────────────┐
│ Step 4: App → MySQL 쿼리                            │
└─────────────────────────────────────────────────────┘

App #2 (10.0.2.20, AZ-C):
  ↓
  JPA Repository → JDBC
  ↓
  jdbc:mysql://10.0.1.234:3306/feedbackdb
  ↓
  Route Table: 10.0.1.234 → local (VPC 내부)
  ↓
  AWS 백본 (AZ-C → AZ-A)
  ↓
  MySQL (10.0.1.234, AZ-A)

MySQL:
  SELECT * FROM feedbacks;
  ↓
  결과 반환 (AZ-A → AZ-C)

┌─────────────────────────────────────────────────────┐
│ Step 5: 응답 반환                                   │
└─────────────────────────────────────────────────────┘

App #2:
  [{"id":1,"content":"피드백1",...}]
  ↓
  HTTP 200 OK
  ↓
ALB (AZ-A):
  응답 전달
  ↓
User:
  JSON 수신 완료!
```

### 시각화

```
Internet
   ↓
┌──────────────────────┐
│ ALB (AZ-A & AZ-C)   │
└────────┬─────────────┘
         │
    ┌────┴───────┐
    │            │
    v            v
┌────────┐  ┌────────┐
│ App #1 │  │ App #2 │
│ AZ-A   │  │ AZ-C   │
│10.0.1.10│ │10.0.2.20│
└────┬───┘  └────┬───┘
     │           │
     │  VPC 내부 통신
     │  (10.0.0.0/16 → local)
     │           │
     └─────┬─────┘
           │
           v
      ┌────────┐
      │ MySQL  │
      │ AZ-A   │
      │10.0.1.234│
      └────────┘

핵심:
  ✅ ALB가 두 App에 트래픽 분산
  ✅ 두 App 모두 동일한 MySQL 접근
  ✅ VPC 내부 통신 (AZ 달라도 OK!)
```

---

## 📋 정리: 질문에 대한 답변

### Q1: 서브넷에 EC2를 하나씩 배치하는 거야?

```
A: 네, 맞습니다! ⭐

ASG 설정:
  - Subnets: Public-AZ-A, Public-AZ-C
  - Desired: 2

ASG 동작:
  → AZ-A에 1개 배치 (10.0.1.10)
  → AZ-C에 1개 배치 (10.0.2.20)

자동 균등 분산! (AZ Balancing)
```

### Q2: ALB가 두 서브넷을 알아서 조율하는 거고?

```
A: 정확합니다! ⭐

ALB 동작:
  1. Target Group에 두 인스턴스 등록
     - 10.0.1.10:8080 (AZ-A)
     - 10.0.2.20:8080 (AZ-C)

  2. 헬스 체크 (30초마다)
     - 두 인스턴스 모두 healthy 확인

  3. 트래픽 분산 (Round Robin)
     - Request 1 → 10.0.1.10
     - Request 2 → 10.0.2.20
     - Request 3 → 10.0.1.10
     ...

→ 알아서 두 인스턴스에 균등 분배!
```

### Q3: MySQL EC2는 어떻게 연결되는 거야?

```
A: VPC 내부 통신으로 연결됩니다! ⭐

MySQL 위치:
  - Public-AZ-A (10.0.1.234)
  - 한 곳에만 고정

App #1 (AZ-A, 10.0.1.10):
  → MySQL (10.0.1.234)
  → 같은 AZ, 같은 Subnet
  → 직접 통신 ✅

App #2 (AZ-C, 10.0.2.20):
  → MySQL (10.0.1.234)
  → 다른 AZ, 다른 Subnet
  → 하지만 VPC 내부! (10.0.0.0/16)
  → Route Table: 10.0.0.0/16 → local
  → AWS 백본 네트워크로 통신 ✅

핵심:
  ✅ VPC 내부면 Subnet/AZ 상관없이 통신 가능!
  ✅ Route Table에 10.0.0.0/16 → local 라우팅
  ✅ Security Group으로 접근 제어
     (db-sg: 3306 ← app-sg만 허용)
```

---

## 🎓 핵심 개념

### 1. ASG AZ Balancing

```
ASG는 인스턴스를 가용 영역에 균등 분산!

Desired: 2, AZ: 2개
  → 각 AZ에 1개씩

Desired: 3, AZ: 2개
  → AZ-A: 2개, AZ-C: 1개
  또는 AZ-A: 1개, AZ-C: 2개

Desired: 4, AZ: 2개
  → 각 AZ에 2개씩

→ 자동으로 균등 분산! ⭐
```

### 2. VPC 내부 통신

```
VPC = 가상 네트워크

VPC 내부 (10.0.0.0/16):
  - Subnet 1: 10.0.1.0/24
  - Subnet 2: 10.0.2.0/24

Route Table:
  10.0.0.0/16 → local

의미:
  - 10.0.1.X ↔ 10.0.2.X 자유롭게 통신
  - Internet Gateway 안 거침
  - AWS 백본 네트워크 (빠름!)
  - Security Group으로만 제어

→ Subnet 달라도 VPC 내부면 OK! ⭐
```

### 3. MySQL Single Point

```
MySQL은 한 곳에만:
  - 10.0.1.234 (AZ-A)

모든 App이 동일한 IP로 연결:
  - App #1 → 10.0.1.234
  - App #2 → 10.0.1.234
  - App #3 → 10.0.1.234

데이터 일관성:
  ✅ 단일 DB이므로 데이터 일관성 보장
  ✅ 동기화 불필요

단점:
  ⚠️ SPOF (Single Point of Failure)
  ⚠️ AZ-A 장애 시 DB 접근 불가

프로덕션이라면:
  - RDS Multi-AZ
  - 또는 Primary-Replica 구성
```

---

## 🎯 최종 정리

```
배치 구조:
┌──────────────────────────────────┐
│ Public-AZ-A (10.0.1.0/24)       │
│   ├─ ALB (자동)                 │
│   ├─ App #1 (ASG 자동) ⭐        │
│   └─ MySQL (수동 고정) ⭐        │
└──────────────────────────────────┘

┌──────────────────────────────────┐
│ Public-AZ-C (10.0.2.0/24)       │
│   ├─ ALB (자동)                 │
│   └─ App #2 (ASG 자동) ⭐        │
└──────────────────────────────────┘

연결:
  User → ALB → App #1 또는 App #2 (로드밸런싱)
  App #1 → MySQL (VPC 내부 통신)
  App #2 → MySQL (VPC 내부 통신)

핵심:
  ✅ ASG가 App을 두 AZ에 균등 분산
  ✅ ALB가 두 App에 트래픽 분산
  ✅ 두 App 모두 동일한 MySQL 접근
  ✅ VPC 내부면 AZ 달라도 통신 가능!
```

**완벽하게 이해하셨습니다!** 🎉
